{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arma11_negloglike' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 208\u001b[0m\n\u001b[1;32m    205\u001b[0m             params_est[asset] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconst\u001b[39m\u001b[38;5;124m\"\u001b[39m: c, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mar.L1\u001b[39m\u001b[38;5;124m\"\u001b[39m: phi, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mma.L1\u001b[39m\u001b[38;5;124m\"\u001b[39m: theta}\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m params_est\n\u001b[0;32m--> 208\u001b[0m arima_params \u001b[38;5;241m=\u001b[39m build_arima_params(TRAIN)\n\u001b[1;32m    209\u001b[0m arima_allocator \u001b[38;5;241m=\u001b[39m ARIMA_Portfolio_Allocator(TRAIN, arima_params, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAllocator\u001b[39;00m():\n",
      "Cell \u001b[0;32mIn[5], line 202\u001b[0m, in \u001b[0;36mbuild_arima_params\u001b[0;34m(price_data)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m asset \u001b[38;5;129;01min\u001b[39;00m returns_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m    201\u001b[0m     y \u001b[38;5;241m=\u001b[39m returns_df[asset]\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# asset return series\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m fit_arma11(y)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fitted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m         c, phi, theta, sigma2 \u001b[38;5;241m=\u001b[39m fitted\n",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m, in \u001b[0;36mfit_arma11\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m     30\u001b[0m x0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, np\u001b[38;5;241m.\u001b[39mvar(y)])\n\u001b[1;32m     31\u001b[0m bounds \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     32\u001b[0m     (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m),       \u001b[38;5;66;03m# c\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.99\u001b[39m, \u001b[38;5;241m0.99\u001b[39m),   \u001b[38;5;66;03m# phi\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.99\u001b[39m, \u001b[38;5;241m0.99\u001b[39m),   \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     (\u001b[38;5;241m1e-8\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)     \u001b[38;5;66;03m# sigma2 must be positive\u001b[39;00m\n\u001b[1;32m     36\u001b[0m ]\n\u001b[0;32m---> 37\u001b[0m res \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39moptimize\u001b[38;5;241m.\u001b[39mminimize(\u001b[38;5;28;01mlambda\u001b[39;00m params: arma11_negloglike(params, y), x0, method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m'\u001b[39m, bounds \u001b[38;5;241m=\u001b[39m bounds)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    711\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:307\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m--> 307\u001b[0m sf \u001b[38;5;241m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[38;5;241m=\u001b[39mjac, args\u001b[38;5;241m=\u001b[39margs, epsilon\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    308\u001b[0m                               bounds\u001b[38;5;241m=\u001b[39mnew_bounds,\n\u001b[1;32m    309\u001b[0m                               finite_diff_rel_step\u001b[38;5;241m=\u001b[39mfinite_diff_rel_step)\n\u001b[1;32m    311\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[1;32m    313\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:383\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    379\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m sf \u001b[38;5;241m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m    384\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[38;5;241m=\u001b[39mepsilon)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m, in \u001b[0;36mfit_arma11.<locals>.<lambda>\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     30\u001b[0m x0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, np\u001b[38;5;241m.\u001b[39mvar(y)])\n\u001b[1;32m     31\u001b[0m bounds \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     32\u001b[0m     (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m),       \u001b[38;5;66;03m# c\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.99\u001b[39m, \u001b[38;5;241m0.99\u001b[39m),   \u001b[38;5;66;03m# phi\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.99\u001b[39m, \u001b[38;5;241m0.99\u001b[39m),   \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     (\u001b[38;5;241m1e-8\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)     \u001b[38;5;66;03m# sigma2 must be positive\u001b[39;00m\n\u001b[1;32m     36\u001b[0m ]\n\u001b[0;32m---> 37\u001b[0m res \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39moptimize\u001b[38;5;241m.\u001b[39mminimize(\u001b[38;5;28;01mlambda\u001b[39;00m params: arma11_negloglike(params, y), x0, method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m'\u001b[39m, bounds \u001b[38;5;241m=\u001b[39m bounds)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mx\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arma11_negloglike' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def arma11_negloglike(params, y):\n",
    "    c, phi, theta, sigma2 = params\n",
    "    n = len(y)\n",
    "    if sigma2 <= 0:\n",
    "        return 1e15\n",
    "    eps = np.zeros(n)\n",
    "    yhat = np.zeros(n)\n",
    "    yhat[0] = c\n",
    "    eps[0] = y[0] - yhat[0]\n",
    "\n",
    "    for t in range(1, n):\n",
    "        yhat[t] = c + phi * y[t - 1] + theta * eps[t-1]\n",
    "        eps[t] = y[t] - yhat[t]\n",
    "\n",
    "    negLL = 0.5 * n * np.log(2 * np.pi * sigma2) + 0.5* np.sum(eps**2) / sigma2\n",
    "    return negLL\n",
    "\n",
    "def fit_arma11(y):\n",
    "    \"\"\"\n",
    "    Fit an ARMA(1, 1) model on the data y by minimizing the neg log likelihood.\n",
    "    Returns the estimated parameters: [c, phi, theta, sigma2]\n",
    "    \"\"\"\n",
    "    x0 = np.array([0.0, 0.1, 0.1, np.var(y)])\n",
    "    bounds = [\n",
    "        (-10, 10),       # c\n",
    "        (-0.99, 0.99),   # phi\n",
    "        (-0.99, 0.99),   # theta\n",
    "        (1e-8, None)     # sigma2 must be positive\n",
    "    ]\n",
    "    res = scipy.optimize.minimize(lambda params: arma11_negloglike(params, y), x0, method = 'L-BFGS-B', bounds = bounds)\n",
    "    if res.success:\n",
    "        return res.x\n",
    "    else:\n",
    "        print(\"Warning: Arma(1,1) fit did not converge\")\n",
    "        return None\n",
    "        \n",
    "\n",
    "class ARIMAForecaster:\n",
    "    \"\"\"\n",
    "    A simplified ARIMA(1,0,1) forecaster that uses offline-fitted parameters.\n",
    "    The parameters for each asset are stored in a dictionary.\n",
    "    \"\"\"\n",
    "    def __init__(self, arima_params):\n",
    "        # arima_params should be a dict structured as:\n",
    "        # { 'Asset_A': {'const': c, 'ar.L1': phi, 'ma.L1': theta}, ... }\n",
    "        self.params = arima_params\n",
    "        self.last_return = {}   # Last observed return for each asset\n",
    "        self.last_resid = {}    # Last forecast error (residual) for each asset\n",
    "\n",
    "    def initialize(self, last_returns):\n",
    "        # last_returns is a dict of the most recent return values for each asset.\n",
    "        for asset, r in last_returns.items():\n",
    "            self.last_return[asset] = r\n",
    "            self.last_resid[asset] = 0.0  # Initialization: assume zero residual at start\n",
    "\n",
    "    def forecast(self):\n",
    "        # Computes one-step-ahead forecasts for all assets.\n",
    "        forecasts = {}\n",
    "        for asset in self.params:\n",
    "            c = self.params[asset]['const']\n",
    "            phi = self.params[asset]['ar.L1']\n",
    "            theta = self.params[asset]['ma.L1']\n",
    "            r_forecast = c + phi * self.last_return[asset] + theta * self.last_resid[asset]\n",
    "            forecasts[asset] = r_forecast\n",
    "        return forecasts\n",
    "\n",
    "    def update(self, observed_returns):\n",
    "        # After observing returns at time T, update the stored values.\n",
    "        for asset, r_actual in observed_returns.items():\n",
    "            c = self.params[asset]['const']\n",
    "            phi = self.params[asset]['ar.L1']\n",
    "            theta = self.params[asset]['ma.L1']\n",
    "            # Forecast we made at last step:\n",
    "            r_hat = c + phi * self.last_return[asset] + theta * self.last_resid[asset]\n",
    "            resid = r_actual - r_hat\n",
    "            self.last_return[asset] = r_actual\n",
    "            self.last_resid[asset] = resid\n",
    "\n",
    "# --- Step 2 & 3: Portfolio Optimization using Forecasted Returns ---\n",
    "def optimize_portfolio(mu_forecast, cov, rf=0.0):\n",
    "    \"\"\"\n",
    "    Given a forecast of returns (mu_forecast) and a covariance matrix (cov),\n",
    "    optimize the portfolio to maximize the Sharpe ratio.\n",
    "    \n",
    "    The optimizer minimizes the negative Sharpe ratio.\n",
    "    \"\"\"\n",
    "    num_assets = len(mu_forecast)\n",
    "    x0 = np.full(num_assets, 1/num_assets)  # equal-weight starting point\n",
    "    \n",
    "    def neg_sharpe(w):\n",
    "        exp_ret = np.dot(w, mu_forecast) - rf\n",
    "        risk = np.sqrt(np.dot(w, np.dot(cov, w)))\n",
    "        if risk < 1e-8:\n",
    "            return 1e6\n",
    "        return - exp_ret / risk\n",
    "    \n",
    "    # Constraints: weights sum to 1 and each weight in [-1, 1]\n",
    "    bounds = [(-1, 1)] * num_assets\n",
    "    cons = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]\n",
    "    \n",
    "    res = scipy.optimize.minimize(neg_sharpe, x0, bounds=bounds, constraints=cons, method=\"SLSQP\")\n",
    "    return res.x if res.success else x0\n",
    "\n",
    "# --- Bringing It All Together ---\n",
    "class ARIMA_Portfolio_Allocator:\n",
    "    def __init__(self, price_data, arima_params, window=100):\n",
    "        \"\"\"\n",
    "        price_data: DataFrame of historical prices (index sorted by time)\n",
    "        arima_params: Offline-fitted ARIMA parameters for each asset (dictionary)\n",
    "        window: number of days to use for covariance estimation\n",
    "        \"\"\"\n",
    "        self.price_data = price_data\n",
    "        # Compute returns from prices:\n",
    "        self.window = window\n",
    "        \n",
    "        # Initialize our ARIMA forecaster with last known returns from training data\n",
    "        self.returns = price_data.pct_change().dropna()\n",
    "        self.assets = self.returns.columns.tolist()\n",
    "        initial_returns = self.returns.iloc[-1].to_dict()\n",
    "        self.forecaster = ARIMAForecaster(arima_params)\n",
    "        self.forecaster.initialize(initial_returns)\n",
    "    \n",
    "    def allocate(self, current_prices):\n",
    "        \"\"\"\n",
    "        Given a row of current prices (as a pandas Series with asset names as index),\n",
    "        compute the portfolio weights for the next period.\n",
    "        \"\"\"\n",
    "        # 1. Forecast returns using the ARIMA model:\n",
    "        forecasted_returns = self.forecaster.forecast()\n",
    "        # Order forecasted returns in the same order as self.assets:\n",
    "        mu_forecast = np.array([forecasted_returns[asset] for asset in self.assets])\n",
    "        \n",
    "        # 2. Estimate covariance matrix from a rolling window of past returns:\n",
    "        if len(self.returns) >= self.window:\n",
    "            recent_returns = self.returns.iloc[-self.window:]\n",
    "        else:\n",
    "            recent_returns = self.returns\n",
    "        cov = np.cov(recent_returns[self.assets].T)\n",
    "        \n",
    "        # 3. Solve the optimization problem:\n",
    "        weights = optimize_portfolio(mu_forecast, cov)\n",
    "        return weights\n",
    "    \n",
    "    def update_with_new_prices(self, new_prices):\n",
    "        \"\"\"\n",
    "        After each new timestep, update the forecaster with the observed returns.\n",
    "        new_prices: A pandas Series or dict with new prices. It must correspond to the assets.\n",
    "        \"\"\"\n",
    "        # Get the last known prices from self.price_data (which should have proper column names)\n",
    "        last_prices = self.price_data.iloc[-1]\n",
    "        \n",
    "        # Compute new returns as percentage changes.\n",
    "        # new_prices should be a Series with asset names matching self.price_data.columns.\n",
    "        new_returns = (new_prices - last_prices) / last_prices\n",
    "        \n",
    "        # Force the index of new_returns to match the asset names exactly.\n",
    "        new_returns.index = self.price_data.columns\n",
    "        \n",
    "        # Convert new_returns to a dict.\n",
    "        returns_dict = new_returns.to_dict()\n",
    "        \n",
    "        # Update the ARIMA forecaster with the observed returns.\n",
    "        self.forecaster.update(returns_dict)\n",
    "        \n",
    "        # Now, update the historical prices. \n",
    "        # Make sure to turn new_prices into a DataFrame with the same columns as self.price_data.\n",
    "        if isinstance(new_prices, pd.Series):\n",
    "            new_prices_df = pd.DataFrame([new_prices], columns=self.price_data.columns)\n",
    "        else:\n",
    "            new_prices_df = new_prices.reindex(columns=self.price_data.columns)\n",
    "        \n",
    "        self.price_data = pd.concat([self.price_data, new_prices_df], ignore_index=True)\n",
    "        \n",
    "data = pd.read_csv('case2.csv', index_col=0)\n",
    "data.reset_index(drop=False, inplace=True)\n",
    "data.rename(columns={\"index\": \"Asset_1\"}, inplace=True)\n",
    "data.index = data.index + 1\n",
    "\n",
    "'''\n",
    "We recommend that you change your train and test split\n",
    "'''\n",
    "\n",
    "TRAIN, TEST = train_test_split(data, test_size = 0.2, shuffle = False)\n",
    "\n",
    "\n",
    "def build_arima_params(price_data):\n",
    "    \"\"\"\n",
    "    Helper function to compute ARMA(1,1) parameters for each asset based on the price data.\n",
    "    We compute returns, then fit the model asset-by-asset.\n",
    "    \"\"\"\n",
    "    returns_df = price_data.pct_change().dropna()\n",
    "    params_est = {}\n",
    "    for asset in returns_df.columns:\n",
    "        y = returns_df[asset].values  # asset return series\n",
    "        fitted = fit_arma11(y)\n",
    "        if fitted is not None:\n",
    "            c, phi, theta, sigma2 = fitted\n",
    "            params_est[asset] = {\"const\": c, \"ar.L1\": phi, \"ma.L1\": theta}\n",
    "    return params_est\n",
    "\n",
    "arima_params = build_arima_params(TRAIN)\n",
    "arima_allocator = ARIMA_Portfolio_Allocator(TRAIN, arima_params, window=100)\n",
    "\n",
    "class Allocator():\n",
    "    def __init__(self, train_data, window = 100):\n",
    "        '''\n",
    "        Anything data you want to store between days must be stored in a class field\n",
    "        '''\n",
    "        \n",
    "        self.running_price_paths = train_data.copy()\n",
    "        \n",
    "        self.train_data = train_data.copy()\n",
    "\n",
    "        self.window = window\n",
    "\n",
    "        self.arima_params = build_arima_params(train_data)\n",
    "\n",
    "        self.allocator = ARIMA_Portfolio_Allocator(train_data, self.arima_params, window=self.window)\n",
    "        \n",
    "        # Do any preprocessing here -- do not touch running_price_paths, it will store the price path up to that data\n",
    "\n",
    "    \n",
    "        \n",
    "    def allocate_portfolio(self, asset_prices):\n",
    "        '''\n",
    "        asset_prices: np array of length 6, prices of the 6 assets on a particular day\n",
    "        weights: np array of length 6, portfolio allocation for the next day\n",
    "        '''\n",
    "    \n",
    "        asset_prices_series = pd.Series(asset_prices, index=self.train_data.columns)\n",
    "\n",
    "        weights = self.allocator.allocate(asset_prices_series)\n",
    "\n",
    "        self.allocator.update_with_new_prices(asset_prices_series)\n",
    "\n",
    "        self.running_price_paths = pd.concat(\n",
    "            [self.running_price_paths, pd.DataFrame([asset_prices_series])],\n",
    "            ignore_index=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        return weights\n",
    "\n",
    "\n",
    "def grading(train_data, test_data): \n",
    "    '''\n",
    "    Grading Script\n",
    "    '''\n",
    "    weights = np.full(shape=(len(test_data.index),6), fill_value=0.0)\n",
    "    alloc = Allocator(train_data)\n",
    "    for i in range(0,len(test_data)):\n",
    "        weights[i,:] = alloc.allocate_portfolio(test_data.iloc[i,:])\n",
    "        if np.sum(weights < -1) or np.sum(weights > 1):\n",
    "            raise Exception(\"Weights Outside of Bounds\")\n",
    "    \n",
    "    capital = [1]\n",
    "    for i in range(len(test_data) - 1):\n",
    "        shares = capital[-1] * weights[i] / np.array(test_data.iloc[i,:])\n",
    "        balance = capital[-1] - np.dot(shares, np.array(test_data.iloc[i,:]))\n",
    "        net_change = np.dot(shares, np.array(test_data.iloc[i+1,:]))\n",
    "        capital.append(balance + net_change)\n",
    "    capital = np.array(capital)\n",
    "    returns = (capital[1:] - capital[:-1]) / capital[:-1]\n",
    "    \n",
    "    if np.std(returns) != 0:\n",
    "        sharpe = np.mean(returns) / np.std(returns)\n",
    "    else:\n",
    "        sharpe = 0\n",
    "        \n",
    "    return sharpe, capital, weights\n",
    "\n",
    "sharpe, capital, weights = grading(TRAIN, TEST)\n",
    "#Sharpe gets printed to command line\n",
    "print(sharpe)\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=80)\n",
    "plt.title(\"Capital\")\n",
    "plt.plot(np.arange(len(TEST)), capital)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=80)\n",
    "plt.title(\"Weights\")\n",
    "plt.plot(np.arange(len(TEST)), weights)\n",
    "plt.legend(TEST.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
